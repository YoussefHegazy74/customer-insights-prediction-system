{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543ca1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from WA_Fn-UseC_-Telco-Customer-Churn.csv...\n",
      "Cleaning data...\n",
      "Data cleaning complete.\n",
      "Starting data transformation and loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win 10-11\\AppData\\Local\\Temp\\ipykernel_9532\\1688693762.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['TotalCharges'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Contracts lookup table.\n",
      "Loaded PaymentMethods lookup table.\n",
      "Loaded Customers tasble.\n",
      "Loaded Accounts table.\n",
      "Loaded CustomerServices table.\n",
      "Loaded EntertainmentServices table.\n",
      "All data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import urllib\n",
    "\n",
    "CSV_FILE_PATH = 'WA_Fn-UseC_-Telco-Customer-Churn.csv'\n",
    "\n",
    "params = urllib.parse.quote_plus(\n",
    "    'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "    'SERVER=localhost;'\n",
    "    'DATABASE=CustomerChurnPrediction;'\n",
    "    'Trusted_Connection=yes;'\n",
    ")\n",
    "DB_CONNECTION_STRING = f'mssql+pyodbc:///?odbc_connect={params}'\n",
    "\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"Performs necessary data cleaning and type conversions.\"\"\"\n",
    "    print(\"Cleaning data...\")\n",
    "    # Convert 'TotalCharges' to numeric, coercing errors to NaN\n",
    "    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "    # Fill any missing TotalCharges (perhaps for new customers) with 0\n",
    "    df['TotalCharges'].fillna(0, inplace=True)\n",
    "\n",
    "    # Convert binary string columns ('Yes'/'No') to actual booleans\n",
    "    # This makes them suitable for BOOLEAN/BIT database columns.\n",
    "    for col in ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Churn',\n",
    "                'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
    "                'StreamingTV', 'StreamingMovies', 'MultipleLines']:\n",
    "        if col in df.columns:\n",
    "            # Map 'Yes' to True, and everything else to False\n",
    "            df[col] = df[col].apply(lambda x: True if x == 'Yes' else False)\n",
    "\n",
    "    # Convert SeniorCitizen from 0/1 to boolean\n",
    "    df['IsSeniorCitizen'] = df['SeniorCitizen'].apply(lambda x: True if x == 1 else False)\n",
    "    \n",
    "    # Convert Gender to 'M' or 'F'\n",
    "    df['gender'] = df['gender'].str.strip().str[0]\n",
    "\n",
    "    print(\"Data cleaning complete.\")\n",
    "    return df\n",
    "\n",
    "           \n",
    "def load_data(engine, df):\n",
    "    \"\"\"Transforms and loads data from the DataFrame into the database tables.\"\"\"\n",
    "    print(\"Starting data transformation and loading...\")\n",
    "    \n",
    "\n",
    "    # 1. Contracts\n",
    "    contract_types = df[['Contract']].drop_duplicates().reset_index(drop=True)\n",
    "    contract_types.rename(columns={'Contract': 'ContractType'}, inplace=True)\n",
    "    # Load data without the index, DB will create IDs\n",
    "    contract_types.to_sql('Contracts', engine, if_exists='append', index=False)\n",
    "    print(\"Loaded Contracts lookup table.\")\n",
    "\n",
    "    # 2. PaymentMethods\n",
    "    payment_methods = df[['PaymentMethod']].drop_duplicates().reset_index(drop=True)\n",
    "    payment_methods.rename(columns={'PaymentMethod': 'PaymentMethodName'}, inplace=True)\n",
    "    # Load data without the index, DB will create IDs\n",
    "    payment_methods.to_sql('PaymentMethods', engine, if_exists='append', index=False)\n",
    "    print(\"Loaded PaymentMethods lookup table.\")\n",
    "\n",
    "    # --- Prepare Main Data by mapping foreign keys ---\n",
    "\n",
    "    # Fetch the lookup tables back from the DB to get the auto-generated IDs\n",
    "    contracts_map = pd.read_sql('SELECT * FROM Contracts', engine).set_index('ContractType')\n",
    "    payment_methods_map = pd.read_sql('SELECT * FROM PaymentMethods', engine).set_index('PaymentMethodName')\n",
    "\n",
    "    # Map the string values to their corresponding integer IDs\n",
    "    df['ContractID'] = df['Contract'].map(contracts_map['ContractID'])\n",
    "    df['PaymentMethodID'] = df['PaymentMethod'].map(payment_methods_map['PaymentMethodID'])\n",
    "\n",
    "    # --- Load Main Tables ---\n",
    "\n",
    "    # 1. Customers Table\n",
    "    customers_df = df[['customerID', 'gender', 'IsSeniorCitizen', 'Partner', 'Dependents']]\n",
    "    customers_df = customers_df.rename(columns={\n",
    "        'customerID': 'CustomerID', 'gender': 'Gender', 'Partner': 'HasPartner', 'Dependents': 'HasDependents'\n",
    "    })\n",
    "    customers_df.to_sql('Customers', engine, if_exists='append', index=False)\n",
    "    print(\"Loaded Customers tasble.\")\n",
    "\n",
    "    # 2. Accounts Table\n",
    "    accounts_df = df[[\n",
    "        'customerID', 'tenure', 'ContractID', 'PaymentMethodID', 'PaperlessBilling',\n",
    "        'MonthlyCharges', 'TotalCharges', 'Churn'\n",
    "    ]]\n",
    "    accounts_df = accounts_df.rename(columns={'customerID': 'CustomerID', 'tenure': 'Tenure'})\n",
    "    accounts_df.to_sql('Accounts', engine, if_exists='append', index=False)\n",
    "    print(\"Loaded Accounts table.\")\n",
    "    \n",
    "    # 3. CustomerServices Table\n",
    "    services_df = df[[\n",
    "        'customerID', 'PhoneService', 'MultipleLines', 'InternetService',\n",
    "        'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport'\n",
    "    ]]\n",
    "    services_df = services_df.rename(columns={'customerID': 'CustomerID'})\n",
    "    services_df.to_sql('CustomerServices', engine, if_exists='append', index=False)\n",
    "    print(\"Loaded CustomerServices table.\")\n",
    "\n",
    "    # 4. EntertainmentServices Table\n",
    "    entertainment_df = df[['customerID', 'StreamingTV', 'StreamingMovies']]\n",
    "    entertainment_df = entertainment_df.rename(columns={'customerID': 'CustomerID'})\n",
    "    entertainment_df.to_sql('EntertainmentServices', engine, if_exists='append', index=False)\n",
    "    print(\"Loaded EntertainmentServices table.\")\n",
    "    \n",
    "    print(\"All data loaded successfully!\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the ETL process.\"\"\"\n",
    "    try:\n",
    "        # Extract\n",
    "        print(f\"Reading data from {CSV_FILE_PATH}...\")\n",
    "        df = pd.read_csv(CSV_FILE_PATH)\n",
    "        # Standardize column names to avoid case-sensitivity issues\n",
    "        df.columns = [col.strip() for col in df.columns]\n",
    "\n",
    "        # Clean\n",
    "        df = clean_data(df)\n",
    "        \n",
    "        # Setup database engine\n",
    "        engine = create_engine(DB_CONNECTION_STRING)\n",
    "        \n",
    "        \n",
    "        # Transform and Load\n",
    "        load_data(engine, df)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{CSV_FILE_PATH}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4433934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyodbc in c:\\users\\win 10-11\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3144cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
